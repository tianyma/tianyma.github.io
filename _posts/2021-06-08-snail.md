---
layout: article
title: "Paper reading: A Simple Neural Attentive Meta-Learner"
date: 2021-06-08
tags: paper review
mathjax: true
key: 2021-06-08-blog
weight: 0
---
## 核心思想
SNAIL结合了temporal convolution和soft attention，是一个model-based meta learning算法。temporal convolution可以直接快速获取大量历史信息，soft attention可以以一种key-value的形式精确定位信息。两者的互补使得SNAIL既可以以高带宽访问历史信息，又可以精确定位到需要的信息。
## 实现过程
SNAIL通过在网络中交替使用temporal convolution layer和 soft attention layer实现。    
具体的，在监督任务中，在$1, ..., t-1$时刻SNAIL依次输入(example, label)对$(x_1, y_1), ..., (x_{t-1}, y_{t-1})$，之后输入一个无标签的example$(x_t, -)$，输出对$x_t$的标签的预测。    
在强化学习任务中，在$1, ..., t-1$时刻SNAIL依次输入(observation, action, reward)对$(o_1, -, -), ..., (o_t, a_{t-1}, r_{t-1})$，然后在$t$时刻输出对$a_t$的分布的预测。在整个学习过程中，跨episode的信息都会被保存下来，从而可以拥有不同episode的泛化能力。
## 测试任务
本文在监督学习和强化学习上都对SNAIL进行了测试，其中监督学习的任务是few-shot image classification，强化学习任务包括multi-armed bandits、Tabular MDPs、3D visual navigation(VizDoom)、Locomotion tasks(mujoco)。

## 创新点
本文将temporal convolution layer和soft attention layer在网络中交替使用，使得二者可以互补，既可以实现对历史信息的高带宽访问，又可以实现精确查找。
## 算法评价
SNAIL是一个典型的model-based meta learning算法，本文对算法的描述思路很清晰，并分别在监督学习任务和强化学习任务上进行了测试。但是，除了模型设计外，meta learning还需要从任务的角度进行分析，这样才能获得更好的任务泛化能力，在lifelong learning这种任务上也有助于解决计算及存储复杂性的问题。

[返回文章列表]({% post_url 2021-05-29-meta-reinforcement-learning %})